{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def evaluate_pairwise(runs: list, example) -> dict:\n",
    "\n",
    "    # 점수 저장\n",
    "    scores = {}\n",
    "    for i, run in enumerate(runs):\n",
    "        scores[run.id] = i\n",
    "    \n",
    "\n",
    "    # 각 예제에 대한 실행 쌍\n",
    "    answer_a = runs[0].outputs[\"answer\"]\n",
    "    answer_b = runs[1].outputs[\"answer\"]\n",
    "    question = example.inputs[\"question\"]\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    grade_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an LLM judge. Compare the following two answers to a question and determine which one is better.\n",
    "        Better answer is the one that is more detailed and informative.\n",
    "        If the answer is not related to the question, it is not a good answer.\n",
    "\n",
    "        \n",
    "        # Question:\n",
    "        {question}\n",
    "        \n",
    "        #Answer A: \n",
    "        {answer_a}\n",
    "        \n",
    "        #Answer B: \n",
    "        {answer_b}\n",
    "        \n",
    "        Output should be either `A` or `B`. Pick the answer that is better.\n",
    "        \n",
    "        #Preference:\n",
    "        \"\"\"\n",
    "    )\n",
    "    answer_grader = grade_prompt | llm | StrOutputParser()\n",
    "\n",
    "    score = answer_grader.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"answer_a\": answer_a,\n",
    "            \"answer_b\": answer_b\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if score == \"A\": # A가 더 답변을 잘했다.\n",
    "        scores[runs[0].id] = 1\n",
    "        scores[runs[1].id] = 0\n",
    "    elif score == \"B\": # B가 더 답변을 잘했다.\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 1\n",
    "    else:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 0\n",
    "        \n",
    "    return {\"key\": \"ranked_preference\", \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag import PDFRAG\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def ask_question_with_llm(llm):\n",
    "\n",
    "    rag = PDFRAG(\n",
    "        \"data/snow-white.pdf\",\n",
    "        llm\n",
    "    )\n",
    "\n",
    "    retriever = rag.create_retriever()\n",
    "\n",
    "    rag_chain = rag.create_chain(retriever)\n",
    "\n",
    "    def _ask_question(inputs: dict):\n",
    "        context = retriever.invoke(inputs[\"question\"])\n",
    "        context = \"\\n\".join([doc.page_content for doc in context])\n",
    "        return {\n",
    "            \"question\": inputs[\"question\"],\n",
    "            \"context\": context,\n",
    "            \"answer\": rag_chain.invoke(inputs[\"question\"])\n",
    "        }\n",
    "    return _ask_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 13, 'total_tokens': 34, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d84d1dc0-cde9-46fd-bbba-69fe33a88e1f-0', usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt3 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "gpt3.invoke(\"안녕하세요?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain_ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.14 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (0.3.14)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-ollama) (0.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.14->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.14->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.14->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.14->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\20109\\miniforge3\\envs\\langchain_env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 👋  \\n\\n무엇을 도와드릴까요? 😊', additional_kwargs={}, response_metadata={'model': 'gemma2', 'created_at': '2024-11-04T05:54:44.9747338Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 3157001700, 'load_duration': 64104900, 'prompt_eval_count': 13, 'prompt_eval_duration': 364349000, 'eval_count': 19, 'eval_duration': 2727027000}, id='run-41bbf29a-6d7e-4c5f-ba56-0702692362bb-0', usage_metadata={'input_tokens': 13, 'output_tokens': 19, 'total_tokens': 32})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Ollama 모델을 불러옴\n",
    "ollama = ChatOllama(model=\"gemma2\")\n",
    "\n",
    "# Ollama 모델 호출\n",
    "ollama.invoke(\"안녕하세요?\")\n",
    "\n",
    "# 응답 출력\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 오늘 날씨는 어때?\n",
      "A: content='죄송합니다. 저는 실시간 정보에 접근할 수 없어서 현재 날씨를 알려드릴 수 없습니다. 날씨 확인을 위해 기상 웹사이트나 앱을 사용해 보세요! 😊' additional_kwargs={} response_metadata={'model': 'gemma2', 'created_at': '2024-11-04T05:55:26.1372414Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 9259345800, 'load_duration': 31052600, 'prompt_eval_count': 17, 'prompt_eval_duration': 1727131000, 'eval_count': 49, 'eval_duration': 7499222000} id='run-6c889c49-de98-4154-af91-6fa02bfd896a-0' usage_metadata={'input_tokens': 17, 'output_tokens': 49, 'total_tokens': 66}\n",
      "\n",
      "Q: 인공지능의 미래는 어떻게 될까?\n",
      "A: content='인공지능의 미래에 대한 예측은 항상 흥미롭고, 다양한 가능성을 가지고 있습니다. 저는 대규모 언어 모델로서 인간의 지식과 창의력을 모방하도록 설계되었지만, 미래를 예측하는 것은 불가능합니다. 그러나 과학 기술 발전 추세와 현재 트렌드를 바탕으로 몇 가지 가능성을 제시해 드릴 수 있습니다.\\n\\n**긍정적인 측면:**\\n\\n* **생활의 질 향상:** 인공지능은 의료 진단, 개인 맞춤형 교육, 자율 주행 기술 등 다양한 분야에서 사람들의 삶을 더욱 편리하고 안전하게 만들 수 있습니다.\\n* **혁신과 창조성 증대:** 인공지능은 새로운 재료 개발, 디자인 설계, 예술 작품 창작 등 창의적인 활동을 지원하여 인류의 지식과 기술 발전을 촉진할 수 있습니다.\\n* **효율성 향상:** 인공지능은 반복적인 작업 자동화를 통해 사람들의 노력을 줄이고 생산성을 높일 수 있습니다.\\n\\n**부정적인 측면:**\\n\\n* **고용 감소:** 인공지능이 자동화하는 작업으로 인해 일자리가 사라질 가능성이 있습니다.\\n* **불평등 심화:** 인공지능 기술과 이로부터 얻는 이익에 대한 접근성 불균형은 사회적 불평등을 악화시킬 수 있습니다.\\n* **윤리적 딜레마:** 인공지능의 윤리적인 사용, 데이터 보안 및 개인 정보 보호 문제 등 해결해야 할 과제가 많습니다.\\n\\n**중요한 것은 다음과 같습니다:**\\n\\n* **책임감 있는 개발과 활용:** 인공지능 기술을 사회적 이익에 기여하고 인간의 권리와 자유를 존중하는 방향으로 개발하고 활용해야 합니다.\\n* **다양성과 포용성 확대:** 인공지능 분야의 다양성을 증진하여 모든 사람이 이러한 기술의 혜택을 누릴 수 있도록 노력해야 합니다.\\n* **지속적인 대화와 공개 논의:** 인공지능의 미래에 대한 전문가, 정책 입안자, 일반 국민 간 지속적인 대화와 공개 논의를 통해 책임감 있는 개발과 활용 방향을 설정해야 합니다.\\n\\n\\n인공지능은 우리 삶에 큰 영향을 미칠 수 있는 강력한 도구입니다. 그 가능성은 무궁무진하지만, 동시에 많은 책임과 과제를 안고 있습니다. 앞으로 인공지능 기술의 발전은 인류가 직면하는 문제들을 해결하고 더 나은 미래를 만들어갈 수 있는 잠재력을 가지고 있지만, 이를 위해서는 전 사회적 노력이 필요합니다.' additional_kwargs={} response_metadata={'model': 'gemma2', 'created_at': '2024-11-04T05:57:57.4331318Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 151293093000, 'load_duration': 28091100, 'prompt_eval_count': 23, 'prompt_eval_duration': 2000500000, 'eval_count': 668, 'eval_duration': 149259783000} id='run-8a35cfa5-34a4-4f41-b01c-e9fb85639a68-0' usage_metadata={'input_tokens': 23, 'output_tokens': 668, 'total_tokens': 691}\n",
      "\n",
      "Q: Python의 장점은 무엇인가요?\n",
      "A: content='## Python의 장점\\n\\nPython은 다양한 분야에서 널리 사용되는 강력하고 유연한 프로그래밍 언어입니다. 그렇게 사랑받는 이유는 다음과 같은 여러 장점 때문입니다.\\n\\n**1. 배우기 쉬움:** \\n\\n* 간결하고 직관적인 문법 구조로, 초보자가도 빠르게 학습할 수 있습니다.\\n* 자연스러운 영어와 유사한 구문이라 이해하기 용이합니다.\\n\\n**2. 풍부한 라이브러리 및 프레임워크:** \\n\\n* 웹 개발(Django, Flask), 데이터 분석(Pandas, NumPy), 머신 러닝(Scikit-learn, TensorFlow) 등 다양한 분야에서 사용할 수 있는 라이브러리가 많이 제공됩니다.\\n* 이를 활용하면 복잡한 작업을 간결하게 구현할 수 있으며 개발 시간을 단축할 수 있습니다.\\n\\n**3. 대규모 커뮤니티 지원:** \\n\\n* 전 세계 많은 개발자가 Python을 사용하고, 활발한 커뮤니티가 존재합니다.\\n* 온라인 포럼, 문서, 교육 자료 등이 풍부하여 문제 해결 및 학습에 도움이 됩니다.\\n\\n**4. 오픈소스 언어:** \\n\\n* 무료로 사용, 배포, 수정할 수 있습니다.\\n* 다양한 플랫폼(Windows, Mac, Linux)에서 실행 가능합니다.\\n\\n**5. 확장성과 유연성:** \\n\\n* 다양한 프로그래밍 스타일을 지원하며(OOP, 함수형), 필요에 따라 언어를 확장할 수 있습니다.\\n\\n\\n## 결론적으로, Python은 배우기 쉬움, 풍부한 라이브러리, 활발한 커뮤니티, 오픈소스 성격 등 다양한 장점이 있어 초보자부터 전문 개발자까지 사랑받는 언어입니다.' additional_kwargs={} response_metadata={'model': 'gemma2', 'created_at': '2024-11-04T05:59:33.6309231Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 96189579300, 'load_duration': 48698600, 'prompt_eval_count': 20, 'prompt_eval_duration': 2469414000, 'eval_count': 430, 'eval_duration': 93669431000} id='run-2bea7ef5-b778-4040-a54d-f81071156314-0' usage_metadata={'input_tokens': 20, 'output_tokens': 430, 'total_tokens': 450}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "questions = [\n",
    "    \"오늘 날씨는 어때?\",\n",
    "    \"인공지능의 미래는 어떻게 될까?\",\n",
    "    \"Python의 장점은 무엇인가요?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    response = ollama.invoke(question)\n",
    "    print(f\"Q: {question}\\nA: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.invoke(\"안녕하세요?\", config={\"max_tokens\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_chain = ask_question_with_llm(ChatOpenAI(model=\"gpt-4o-mini\", temperature=0))\n",
    "gpt3_chain = ask_question_with_llm(ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0))\n",
    "\n",
    "# ollama 사용시\n",
    "# ollama_chain = ask_question_with_llm(ChatOllama(model=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'MODEL_COMPARE_EVALUATION-256328d6' at:\n",
      "https://smith.langchain.com/o/4f4b6069-9fa7-4219-889b-6de7c9b52ea4/datasets/d27aef40-c129-4c8c-85da-f16249bcb82f/compare?selectedSessions=2b3ec683-2ba4-4c2d-92af-6ff8af908451\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308f526d631b479b8308654f95be4e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'MODEL_COMPARE_EVALUATION-8db0a31c' at:\n",
      "https://smith.langchain.com/o/4f4b6069-9fa7-4219-889b-6de7c9b52ea4/datasets/d27aef40-c129-4c8c-85da-f16249bcb82f/compare?selectedSessions=eecfec86-ee46-4697-bf49-15f09455b80d\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36aa28a91313432da9ee27b9cee02d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "cot_qa_evaluator = LangChainStringEvaluator(\n",
    "    \"cot_qa\",\n",
    "    config={\"llm\": ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)}, # 평가자\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],\n",
    "        \"reference\": run.outputs[\"context\"],\n",
    "        \"input\": example.inputs[\"question\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset_name = \"RAG_EVALUATION_DATASET\"\n",
    "\n",
    "experiment_result1 = evaluate(\n",
    "    gpt3_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[cot_qa_evaluator],\n",
    "    experiment_prefix=\"MODEL_COMPARE_EVALUATION\",\n",
    "    metadata={\n",
    "        \"variant\": \"GPT-3.5-turbo 평가 (cot_qa)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "experiment_result2 = evaluate(\n",
    "    gpt4o_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[cot_qa_evaluator],\n",
    "    experiment_prefix=\"MODEL_COMPARE_EVALUATION\",\n",
    "    metadata={\n",
    "        \"variant\": \"GPT-4o-mini 평가 (cot_qa)\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/4f4b6069-9fa7-4219-889b-6de7c9b52ea4/datasets/d27aef40-c129-4c8c-85da-f16249bcb82f/compare?selectedSessions=2b3ec683-2ba4-4c2d-92af-6ff8af908451%2Ceecfec86-ee46-4697-bf49-15f09455b80d&comparativeExperiment=458c97a7-5502-4271-b8dc-a94cf8342fb1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f6ffc43a6947f3aa4fbabefc68d28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<langsmith.evaluation._runner.ComparativeExperimentResults at 0x226b1ae00d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate_comparative\n",
    "\n",
    "evaluate_comparative(\n",
    "    [\"MODEL_COMPARE_EVALUATION-256328d6\",\"MODEL_COMPARE_EVALUATION-8db0a31c\"],\n",
    "    # 평가자\n",
    "     evaluators=[evaluate_pairwise]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
